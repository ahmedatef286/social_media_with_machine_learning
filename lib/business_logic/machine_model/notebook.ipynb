{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import string\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('labeled_data.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            0\n",
       "count                 0\n",
       "hate_speech           0\n",
       "offensive_language    0\n",
       "neither               0\n",
       "class                 0\n",
       "tweet                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check null values\n",
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  \\\n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
      "5  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...   \n",
      "6  !!!!!!\"@__BrighterDays: I can not just sit up ...   \n",
      "7  !!!!&#8220;@selfiequeenbri: cause I'm tired of...   \n",
      "8  \" &amp; you might not get ya bitch back &amp; ...   \n",
      "9  \" @rhythmixx_ :hobbies include: fighting Maria...   \n",
      "\n",
      "                                    processed_tweets  \n",
      "0  woman complain clean hous amp man alway take t...  \n",
      "1  boy dat cold tyga dwn bad cuffin dat hoe st place  \n",
      "2         dawg ever fuck bitch start cri confus shit  \n",
      "3                                   look like tranni  \n",
      "4     shit hear might true might faker bitch told ya  \n",
      "5      shit blow claim faith somebodi still fuck hoe  \n",
      "6              sit hate anoth bitch got much shit go  \n",
      "7            caus tire big bitch come us skinni girl  \n",
      "8               amp might get ya bitch back amp that  \n",
      "9                    hobbi includ fight mariam bitch  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "#extending the stopwords to include other words used in twitter such as retweet(rt) etc.\n",
    "other_exclusions = [\"#ff\", \"ff\", \"rt\" , \"RT\"]\n",
    "stopwords.extend(other_exclusions)\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess(tweet):  \n",
    "    # removal of extra spaces\n",
    "    regex_pat = re.compile(r'\\s+')\n",
    "    tweet_space = tweet.str.replace(regex_pat, ' ' , regex=True)\n",
    "\n",
    "    # removal of @name[mention]\n",
    "    regex_pat = re.compile(r'@[\\w\\-]+')\n",
    "    tweet_name = tweet_space.str.replace(regex_pat, '' , regex=True)\n",
    "\n",
    "    # removal of links[https://abc.com]\n",
    "    giant_url_regex =  re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "            r'[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    tweets = tweet_name.str.replace(giant_url_regex, '', regex=True)\n",
    "    \n",
    "    # removal of punctuations and numbers\n",
    "    punc_remove = tweets.str.replace(r\"[^a-zA-Z]\", \" \", regex=True)\n",
    "    # remove whitespace with a single space\n",
    "    newtweet=punc_remove.str.replace(r'\\s+', ' ', regex=True)\n",
    "    # remove leading and trailing whitespace\n",
    "    newtweet=newtweet.str.replace(r'^\\s+|\\s+?$','', regex=True)\n",
    "    # replace normal numbers with numbr\n",
    "    newtweet=newtweet.str.replace(r'\\d+(\\.\\d+)?','numbr', regex=True)\n",
    "    # removal of capitalization\n",
    "    tweet_lower = newtweet.str.lower()\n",
    "    \n",
    "    # tokenizing\n",
    "    tokenized_tweet = tweet_lower.apply(lambda x: x.split())\n",
    "    \n",
    "    # removal of stopwords\n",
    "    tokenized_tweet=  tokenized_tweet.apply(lambda x: [item for item in x if item not in stopwords])\n",
    "    \n",
    "    # stemming of the tweets\n",
    "    tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) \n",
    "    \n",
    "    for i in range(len(tokenized_tweet)):\n",
    "        tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
    "        tweets_p= tokenized_tweet\n",
    "    \n",
    "    return tweets_p\n",
    "    \n",
    "processed_tweets = preprocess(df.tweet)   \n",
    "\n",
    "df['processed_tweets'] = processed_tweets\n",
    "print(df[[\"tweet\",\"processed_tweets\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8908614081097438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       290\n",
      "           1       0.88      1.00      0.93      3832\n",
      "           2       1.00      0.70      0.82       835\n",
      "\n",
      "    accuracy                           0.89      4957\n",
      "   macro avg       0.62      0.57      0.59      4957\n",
      "weighted avg       0.85      0.89      0.86      4957\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Assume 'df' is your DataFrame with the dataset\n",
    "X = df[['processed_tweets', 'count', 'offensive_language', 'hate_speech' , 'neither']]\n",
    "y = df['class']\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Convert text to numerical features using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['processed_tweets'])\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val['processed_tweets'])\n",
    "\n",
    "# Concatenate TF-IDF features with other numerical features\n",
    "X_train_final = X_train[['count', 'offensive_language', 'hate_speech','neither']].values\n",
    "X_train_final = hstack([X_train_tfidf, X_train_final])\n",
    "X_val_final = X_val[['count', 'offensive_language', 'hate_speech','neither']].values\n",
    "X_val_final = hstack([X_val_tfidf, X_val_final])\n",
    "\n",
    "# Train a model (e.g., RandomForestClassifier)\n",
    "clf =  LogisticRegression(random_state=42, max_iter=500, C=0.00005)\n",
    "clf.fit(X_train_final, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = clf.predict(X_val_final)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(classification_report(y_val, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction for the sentence is: 1\n"
     ]
    }
   ],
   "source": [
    "# Example sentence\n",
    "new_sentence ='i love women'\n",
    "\n",
    "# Preprocess the new sentence\n",
    "new_sentence = new_sentence.lower()\n",
    "new_sentence = pd.Series(new_sentence).replace('[^a-zA-Z0-9]', ' ', regex=True)[0]\n",
    "\n",
    "# Convert the new sentence to TF-IDF features\n",
    "new_sentence_tfidf = tfidf_vectorizer.transform([new_sentence])\n",
    "\n",
    "# Add other numerical features if needed\n",
    "# Example:\n",
    "new_numerical_features = [0, 0, 0, 0]  # Replace with your own numerical features\n",
    "new_sentence_final = hstack([new_sentence_tfidf, new_numerical_features])\n",
    "\n",
    "# Make predictions for the new sentence\n",
    "prediction = clf.predict(new_sentence_final)\n",
    "\n",
    "# Print the prediction\n",
    "print(f\"The prediction for the sentence is: {prediction[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
